{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "998cee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adamc\\miniconda3\\envs\\magenta_legacy\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "c:\\Users\\adamc\\miniconda3\\envs\\magenta_legacy\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "c:\\Users\\adamc\\miniconda3\\envs\\magenta_legacy\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import urllib.request\n",
    "from importlib import reload\n",
    "from magenta.models.melody_rnn import melody_rnn_model\n",
    "from magenta.models.melody_rnn import melody_rnn_sequence_generator\n",
    "from magenta.models.shared import sequence_generator_bundle\n",
    "from magenta.models.rl_tuner import rl_tuner\n",
    "from magenta.models.rl_tuner import rl_tuner_ops\n",
    "from note_seq import midi_io\n",
    "from note_seq.protobuf import music_pb2, generator_pb2\n",
    "import note_seq\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b264fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\adamc\\miniconda3\\envs\\magenta_legacy\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Loading pre-trained basic_rnn model...\n",
      "  âœ“ Using cached model: C:\\Users\\adamc\\.magenta\\models\\basic_rnn.mag\n"
     ]
    }
   ],
   "source": [
    "# Disable TF v2 behavior for compatibility\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "# Configuration\n",
    "CONFIG = 'basic_rnn'  #Note_RNN\n",
    "MELODY_RNN_SAVE_PATH = \"./melody_rnn_finetuned/\"\n",
    "\n",
    "# Create save directory\n",
    "os.makedirs(MELODY_RNN_SAVE_PATH, exist_ok=True)\n",
    "\n",
    "# Download and load pre-trained Melody_RNN model\n",
    "model_cache_dir = pathlib.Path.home() / '.magenta' / 'models'\n",
    "model_cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "bundle_file = model_cache_dir / f'{CONFIG}.mag'\n",
    "\n",
    "print(f\"Loading pre-trained {CONFIG} model...\")\n",
    "\n",
    "if not bundle_file.exists():\n",
    "    print(f\"  Downloading {CONFIG} model...\")\n",
    "    bundle_url = f'http://download.magenta.tensorflow.org/models/{CONFIG}.mag'\n",
    "    try:\n",
    "        urllib.request.urlretrieve(bundle_url, str(bundle_file))\n",
    "        print(f\"  âœ“ Downloaded to {bundle_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        raise\n",
    "else:\n",
    "    print(f\"  âœ“ Using cached model: {bundle_file}\")\n",
    "\n",
    "# Load the bundle\n",
    "config = melody_rnn_model.default_configs[CONFIG]\n",
    "config.hparams.parse('')\n",
    "bundle = sequence_generator_bundle.read_bundle_file(str(bundle_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd0e53",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Fine-Tuning Pipeline\n",
    "\n",
    "This section handles data preparation and model fine-tuning for artist-specific models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc9888e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINE-TUNING MODELS\n",
      "============================================================\n",
      "\n",
      "ðŸŽ¹ Fine-tuning for ABBA...\n",
      "  Learning rate: 0.0001\n",
      "  Training steps: 5000\n",
      "  Batch size: 32\n",
      "\n",
      "  Starting training...\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MelodyRnnModel' object has no attribute 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 133\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâš  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in preprocessed data, skipping\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfine_tune_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtfrecord_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mFINETUNE_CONFIG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMELODY_RNN_SAVE_PATH\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     finetune_results[artist] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 66\u001b[0m, in \u001b[0;36mfine_tune_model\u001b[1;34m(artist_name, tfrecord_path, config, output_dir)\u001b[0m\n\u001b[0;32m     63\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mAdamOptimizer(learning_rate\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Get loss (cross-entropy on sequences)\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m train_op \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mminimize(\u001b[43mmelody_rnn_model_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_steps\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MelodyRnnModel' object has no attribute 'loss'"
     ]
    }
   ],
   "source": [
    "## Step 3: Fine-Tune Model on Artist-Specific Data\n",
    "\n",
    "# Fine-tuning configuration\n",
    "FINETUNE_CONFIG = {\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 32,\n",
    "    'num_steps': 5000,\n",
    "    'steps_per_checkpoint': 500,\n",
    "}\n",
    "\n",
    "def fine_tune_melody_rnn(artist_name, tfrecord_path, config, output_dir):\n",
    "    \"\"\"\n",
    "    Fine-tune Melody_RNN using Magenta's training pipeline.\n",
    "    \n",
    "    Args:\n",
    "        artist_name: name of the artist\n",
    "        tfrecord_path: path to TFRecord training data\n",
    "        config: training configuration dict\n",
    "        output_dir: where to save fine-tuned model\n",
    "    \"\"\"\n",
    "    import subprocess\n",
    "    \n",
    "    print(f\"\\nðŸŽ¹ Fine-tuning for {artist_name}...\")\n",
    "    print(f\"  Learning rate: {config['learning_rate']}\")\n",
    "    print(f\"  Training steps: {config['num_steps']}\")\n",
    "    print(f\"  Batch size: {config['batch_size']}\")\n",
    "    \n",
    "    # Create output directory for this artist\n",
    "    artist_model_dir = os.path.join(output_dir, artist_name)\n",
    "    os.makedirs(artist_model_dir, exist_ok=True)\n",
    "    train_dir = os.path.join(artist_model_dir, 'train')\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    \n",
    "    # Get bundle file path\n",
    "    model_cache_dir = pathlib.Path.home() / '.magenta' / 'models'\n",
    "    bundle_file = model_cache_dir / f'{CONFIG}.mag'\n",
    "    \n",
    "    print(f\"\\n  Starting training...\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Use Magenta's melody_rnn_train script\n",
    "        cmd = [\n",
    "            'melody_rnn_train',\n",
    "            f'--config={CONFIG}',\n",
    "            f'--bundle_file={str(bundle_file)}',\n",
    "            f'--output_dir={train_dir}',\n",
    "            f'--num_training_steps={config[\"num_steps\"]}',\n",
    "            f'--batch_size={config[\"batch_size\"]}',\n",
    "            f'--learning_rate={config[\"learning_rate\"]}',\n",
    "            f'--tfrecord_path={tfrecord_path}',\n",
    "        ]\n",
    "        \n",
    "        # Run training\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"  âœ“ Training completed successfully\")\n",
    "            final_checkpoint = os.path.join(train_dir, f'model.ckpt-{config[\"num_steps\"]}')\n",
    "        else:\n",
    "            print(f\"  âš  Training output:\")\n",
    "            print(result.stdout)\n",
    "            print(result.stderr)\n",
    "            final_checkpoint = os.path.join(train_dir, 'model.ckpt-0')\n",
    "        \n",
    "        print(f\"  Final checkpoint: {final_checkpoint}\")\n",
    "        \n",
    "        return {\n",
    "            'artist': artist_name,\n",
    "            'train_dir': train_dir,\n",
    "            'final_checkpoint': final_checkpoint,\n",
    "            'steps_trained': config['num_steps'],\n",
    "        }\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"  âš  melody_rnn_train command not found\")\n",
    "        print(f\"  Install Magenta: pip install magenta\")\n",
    "        # Fallback: create checkpoint directory structure\n",
    "        final_checkpoint = os.path.join(train_dir, 'model.ckpt-0')\n",
    "        os.makedirs(train_dir, exist_ok=True)\n",
    "        return {\n",
    "            'artist': artist_name,\n",
    "            'train_dir': train_dir,\n",
    "            'final_checkpoint': final_checkpoint,\n",
    "            'steps_trained': 0,\n",
    "        }\n",
    "\n",
    "# Fine-tune for selected artist\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINE-TUNING MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ARTISTS_TO_FINETUNE = ['ABBA']\n",
    "\n",
    "finetune_results = {}\n",
    "tfrecord_info = {'ABBA': 100}\n",
    "\n",
    "for artist in ARTISTS_TO_FINETUNE:\n",
    "    tfrecord_path = os.path.join(\"./MIDI/Artist_MIDI/training_data\", f'{artist}_melodies.tfrecord')\n",
    "    \n",
    "    if artist not in tfrecord_info:\n",
    "        print(f\"âš  {artist} not in preprocessed data, skipping\")\n",
    "        continue\n",
    "    \n",
    "    if not os.path.exists(tfrecord_path):\n",
    "        print(f\"âš  {artist} TFRecord not found, skipping\")\n",
    "        continue\n",
    "    \n",
    "    result = fine_tune_melody_rnn(\n",
    "        artist,\n",
    "        tfrecord_path,\n",
    "        FINETUNE_CONFIG,\n",
    "        MELODY_RNN_SAVE_PATH\n",
    "    )\n",
    "    \n",
    "    finetune_results[artist] = result\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINE-TUNING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for artist, result in finetune_results.items():\n",
    "    print(f\"\\n{artist}:\")\n",
    "    print(f\"  Steps trained: {result['steps_trained']}\")\n",
    "    print(f\"  Train directory: {result['train_dir']}\")\n",
    "    print(f\"  Checkpoint: {result['final_checkpoint']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4158cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Load Fine-Tuned Model for Generation\n",
    "\n",
    "# Choose which model to use for generation\n",
    "USE_FINETUNED = False  # Set to True to use fine-tuned model\n",
    "FINETUNED_ARTIST = 'Billy_Joel'  # Which artist's model to use\n",
    "\n",
    "if USE_FINETUNED and FINETUNED_ARTIST in finetune_results:\n",
    "    # Use fine-tuned model\n",
    "    result = finetune_results[FINETUNED_ARTIST]\n",
    "    checkpoint_path = result['final_checkpoint']\n",
    "    \n",
    "    print(f\"âœ“ Using fine-tuned model for {FINETUNED_ARTIST}\")\n",
    "    print(f\"  Checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    # Load fine-tuned bundle\n",
    "    generation_bundle = bundle  # Use same bundle but with fine-tuned weights\n",
    "    generation_model = melody_rnn_model.MelodyRnnModel(config)\n",
    "    \n",
    "    # Note: To fully use fine-tuned checkpoint, would need to construct\n",
    "    # a generator with the checkpoint. For now, we'll use pre-trained.\n",
    "    print(\"  Note: Generation will use pre-trained model for now\")\n",
    "    print(\"  Full checkpoint restoration requires custom setup\")\n",
    "else:\n",
    "    # Use pre-trained model\n",
    "    print(\"âœ“ Using pre-trained Melody_RNN model\")\n",
    "    generation_bundle = bundle\n",
    "    generation_model = melody_rnn_model.MelodyRnnModel(config)\n",
    "\n",
    "print(f\"\\nModel ready for generation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3d9c439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¹ Generating 20 melody candidates...\n",
      "\n",
      "WARNING:tensorflow:The saved meta_graph is possibly from an older release:\n",
      "'model_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\adamc\\AppData\\Local\\Temp\\tmp6etxwpy9\\model.ckpt\n",
      "  [ 1] Generation failed: SequenceGeneratorError: Got GenerateSection request for section that is before the end of the NoteSequence. This model can only extend sequences. Requested start time: 0.0, Final note end time: 1.5\n",
      "\n",
      "âœ“ Generated 0 valid melodies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adamc\\AppData\\Local\\Temp\\ipykernel_22408\\1491662270.py\", line 49, in <module>\n",
      "    generated_sequence = sequence_generator.generate(primer_sequence, generator_options)\n",
      "  File \"c:\\Users\\adamc\\miniconda3\\envs\\magenta_legacy\\lib\\site-packages\\magenta\\models\\shared\\sequence_generator.py\", line 194, in generate\n",
      "    return self._generate(input_sequence, generator_options)\n",
      "  File \"c:\\Users\\adamc\\miniconda3\\envs\\magenta_legacy\\lib\\site-packages\\magenta\\models\\melody_rnn\\melody_rnn_sequence_generator.py\", line 80, in _generate\n",
      "    raise sequence_generator.SequenceGeneratorError(\n",
      "magenta.models.shared.sequence_generator.SequenceGeneratorError: Got GenerateSection request for section that is before the end of the NoteSequence. This model can only extend sequences. Requested start time: 0.0, Final note end time: 1.5\n"
     ]
    }
   ],
   "source": [
    "# Create sequence generator from the loaded bundle\n",
    "details = bundle.generator_details\n",
    "model = melody_rnn_model.MelodyRnnModel(config)\n",
    "\n",
    "sequence_generator = melody_rnn_sequence_generator.MelodyRnnSequenceGenerator(\n",
    "    model=model,\n",
    "    details=config.details,\n",
    "    steps_per_quarter=config.steps_per_second,\n",
    "    checkpoint=None,\n",
    "    bundle=bundle,\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸŽ¹ Generating {NUM_GENERATIONS} melody candidates...\\n\")\n",
    "\n",
    "generated_melodies = []\n",
    "generated_sequences = []\n",
    "\n",
    "for i in range(NUM_GENERATIONS):\n",
    "    try:\n",
    "        # Create a primer sequence with starting notes\n",
    "        primer_notes = [60, 64, 67]  # C-E-G\n",
    "        primer_sequence = note_seq.NoteSequence()\n",
    "        \n",
    "        current_time = 0\n",
    "        note_duration = 0.5  # Quarter note\n",
    "        \n",
    "        for pitch in primer_notes:\n",
    "            note = primer_sequence.notes.add()\n",
    "            note.start_time = current_time\n",
    "            note.end_time = current_time + note_duration\n",
    "            note.pitch = pitch\n",
    "            note.velocity = 80\n",
    "            current_time += note_duration\n",
    "        \n",
    "        # Create GeneratorOptions\n",
    "        generator_options = generator_pb2.GeneratorOptions()\n",
    "\n",
    "        # Calculate generate time\n",
    "        seconds_per_step = 1.0 / sequence_generator.steps_per_quarter\n",
    "        generate_end_time = primer_sequence.total_time + (NUM_STEPS * seconds_per_step)\n",
    "\n",
    "        # Set generation section (from end of primer, extending forward)\n",
    "        generate_section = generator_options.generate_sections.add()\n",
    "        generate_section.start_time = primer_sequence.total_time\n",
    "        generate_section.end_time = generate_end_time\n",
    "\n",
    "        # Set temperature\n",
    "        generator_options.args['temperature'].float_value = TEMPERATURE\n",
    "        generated_sequence = sequence_generator.generate(primer_sequence, generator_options)\n",
    "        \n",
    "        # Extract note sequence (skip primer notes, keep only generated notes)\n",
    "        if generated_sequence and len(generated_sequence.notes) > len(primer_notes):\n",
    "            notes = [int(note.pitch) for note in generated_sequence.notes[len(primer_notes):]]\n",
    "            \n",
    "            if len(notes) > 3:  # Only keep melodies with enough notes\n",
    "                generated_melodies.append(notes)\n",
    "                generated_sequences.append(generated_sequence)\n",
    "                \n",
    "                # Score this melody\n",
    "                score = evaluator.evaluate(notes)\n",
    "                print(f\"  [{i+1:2d}] Generated melody ({len(notes)} notes) - Score: {score:.1f}/100\")\n",
    "\n",
    "    except Exception as e:\n",
    "        if i == 0:  # Show detailed error on first failure\n",
    "            print(f\"  [{i+1:2d}] Generation failed: {type(e).__name__}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(f\"\\nâœ“ Generated {len(generated_melodies)} valid melodies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fc6d80",
   "metadata": {},
   "source": [
    "## Score and Rank Generated Melodies\n",
    "\n",
    "Evaluate all generated melodies and rank them by quality score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Analyzing generated melodies...\\n\")\n",
    "\n",
    "# Score all melodies\n",
    "scores = []\n",
    "for i, melody in enumerate(generated_melodies):\n",
    "    score = evaluator.evaluate(melody)\n",
    "    scores.append({\n",
    "        'index': i,\n",
    "        'score': score,\n",
    "        'notes': melody,\n",
    "        'length': len(melody),\n",
    "        'unique_pitches': len(set(melody))\n",
    "    })\n",
    "\n",
    "# Sort by score (highest first)\n",
    "scores_sorted = sorted(scores, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "print(\"âœ“ Top Melodies by Quality Score:\\n\")\n",
    "print(f\"{'Rank':<6} {'Score':<8} {'Length':<8} {'Unique':<8} {'Range':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for rank, entry in enumerate(scores_sorted[:10], 1):\n",
    "    melody = entry['notes']\n",
    "    pitch_range = max(melody) - min(melody) if melody else 0\n",
    "    print(f\"{rank:<6} {entry['score']:<8.1f} {entry['length']:<8} {entry['unique_pitches']:<8} {pitch_range:<10}\")\n",
    "\n",
    "print(f\"\\nAverage Score: {np.mean([s['score'] for s in scores]):.1f}/100\")\n",
    "print(f\"Best Score: {scores_sorted[0]['score']:.1f}/100\")\n",
    "print(f\"Worst Score: {scores_sorted[-1]['score']:.1f}/100\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a8dfac",
   "metadata": {},
   "source": [
    "## Save Top Melodies as MIDI\n",
    "\n",
    "Export the best scoring melodies as playable MIDI files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef87cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"./improved_melodies/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"\\nðŸ’¾ Saving top melodies as MIDI files...\\n\")\n",
    "\n",
    "# Save top 5 melodies\n",
    "num_to_save = min(5, len(scores_sorted))\n",
    "\n",
    "for rank, entry in enumerate(scores_sorted[:num_to_save], 1):\n",
    "    melody_notes = entry['notes']\n",
    "    score = entry['score']\n",
    "    \n",
    "    # Create a Music Sequence with timing\n",
    "    sequence = note_seq.Sequence()\n",
    "    sequence.tempo = 120  # BPM\n",
    "    \n",
    "    # Add notes with timing (quarter note = 0.5 beats at 120 BPM = 0.5 seconds)\n",
    "    current_time = 0\n",
    "    note_duration = 0.5  # Quarter note in seconds\n",
    "    \n",
    "    for pitch in melody_notes:\n",
    "        note = sequence.notes.add()\n",
    "        note.start_time = current_time\n",
    "        note.end_time = current_time + note_duration\n",
    "        note.pitch = int(pitch)\n",
    "        note.velocity = 80\n",
    "        current_time += note_duration\n",
    "    \n",
    "    # Save as MIDI\n",
    "    filename = f\"{output_dir}top_{rank}_score_{score:.0f}.mid\"\n",
    "    midi_io.note_sequence_to_midi_file(sequence, filename)\n",
    "    print(f\"  âœ“ Saved: {filename} (Score: {score:.1f}/100)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"âœ“ Melody generation complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest melodies saved to: {output_dir}\")\n",
    "print(f\"\\nTop 5 Scores:\")\n",
    "for rank, entry in enumerate(scores_sorted[:5], 1):\n",
    "    print(f\"  {rank}. Score: {entry['score']:.1f}/100 - {len(entry['notes'])} notes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67dad9d",
   "metadata": {},
   "source": [
    "## Tune Music Theory Constraints\n",
    "\n",
    "Adjust constraint weights to change melody generation characteristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47634c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different constraint weights\n",
    "print(\"\\nðŸ“ Tips for tuning music theory constraints:\\n\")\n",
    "\n",
    "print(\"Current constraint_weights:\")\n",
    "for key, value in constraint_weights.items():\n",
    "    print(f\"  '{key}': {value}\")\n",
    "\n",
    "print(\"\\nTo emphasize different characteristics, adjust weights:\")\n",
    "print(\"  - Increase 'smooth_intervals' for more stepwise motion\")\n",
    "print(\"  - Increase 'pitch_range' for more varied pitches\")\n",
    "print(\"  - Increase 'resolution' to prefer strong endings\")\n",
    "print(\"  - Decrease 'repetition' weight for more varied notes\")\n",
    "\n",
    "print(\"\\nExample: More stepwise, fewer leaps\")\n",
    "print(\"  constraint_weights['smooth_intervals'] = 3.5  # Was 2.0\")\n",
    "print(\"  constraint_weights['pitch_range'] = 1.0       # Was 1.5\")\n",
    "print(\"  evaluator = MelodyEvaluator(constraint_weights)\")\n",
    "\n",
    "print(\"\\nExample: More variety and uniqueness\")\n",
    "print(\"  constraint_weights['pitch_range'] = 2.5\")\n",
    "print(\"  constraint_weights['repetition'] = 0.3\")\n",
    "print(\"  evaluator = MelodyEvaluator(constraint_weights)\")\n",
    "\n",
    "print(\"\\nThen re-run the generation cells to see how outputs change!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magenta_legacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
